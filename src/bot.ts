/**
 * bot.ts â€” Telegram bot with security-first design
 *
 * Security model:
 *   1. User ID whitelist â€” only responds to ALLOWED_USER_IDS
 *   2. Long-polling only â€” no web server, no exposed ports, no HTTP
 *   3. Graceful error handling â€” never leaks internals to Telegram
 */

import { Bot, InputFile } from "grammy";
import { TELEGRAM_BOT_TOKEN, ALLOWED_USER_IDS, LLM_MODEL } from "./config.js";
import { runAgent, clearHistory } from "./agent.js";
import { transcribeAudio } from "./transcribe.js";
import { getUsageSummary } from "./usage.js";
import { countMessages, pruneHistory } from "./memory.js";
import { textToSpeech, isTTSAvailable } from "./tts.js";

// â”€â”€ Bot started time (for /status) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const BOT_START_TIME = Date.now();

// â”€â”€ Per-user voice mode toggle (true = reply with audio) â”€
const voiceModeEnabled: Map<number, boolean> = new Map();
function isVoiceMode(chatId: number): boolean {
    return voiceModeEnabled.get(chatId) ?? false;
}

// â”€â”€ Create Bot (long-polling, NO webhooks) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export const bot = new Bot(TELEGRAM_BOT_TOKEN);

// â”€â”€ Security Middleware â€” runs before EVERY handler â”€â”€â”€â”€â”€
bot.use(async (ctx, next) => {
    const userId = ctx.from?.id;

    // Silently ignore messages from unauthorized users
    if (!userId || !ALLOWED_USER_IDS.includes(userId)) {
        return;
    }

    await next();
});

// â”€â”€ /start command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("start", async (ctx) => {
    await ctx.reply(
        `ğŸª **Gravity Claw** is online.\n\n` +
        `I'm your personal AI assistant with voice, web search, and file access.\n\n` +
        `**Commands:**\n` +
        `  /voice â€” Toggle Alexandra voice mode ğŸ¤\n` +
        `  /status â€” System health & uptime\n` +
        `  /new â€” Clear conversation and start fresh\n` +
        `  /compact â€” Summarize & compress context\n` +
        `  /usage â€” Token & cost statistics\n` +
        `  /model â€” Show current AI model\n` +
        `  /help â€” Full command list\n\n` +
        `_Phase 3 â€” Voice: ElevenLabs TTS (Alexandra)_`,
        { parse_mode: "Markdown" }
    );
});

// â”€â”€ /help command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("help", async (ctx) => {
    await ctx.reply(
        `ğŸª **Gravity Claw** â€” Commands\n\n` +
        `*ğŸ¤ Voice:*\n` +
        `  /voice â€” Toggle Alexandra voice mode on/off\n\n` +
        `*ğŸ§  Core:*\n` +
        `  /status â€” System health, uptime, memory stats\n` +
        `  /new â€” Clear conversation history\n` +
        `  /compact â€” Auto-summarize and compress history\n` +
        `  /usage â€” Show token usage and estimated cost\n` +
        `  /model â€” Show which AI model is active\n` +
        `  /ping â€” Check if I'm alive\n\n` +
        `*ğŸ’¾ Memory:*\n` +
        `  Conversations saved to SQLite â€” I remember everything!\n\n` +
        `*ğŸ” Search & Tools:*\n` +
        `  I can search the web, run shell commands, and read/write files.\n\n` +
        `Just send me a message and I'll handle it. ğŸš€`,
        { parse_mode: "Markdown" }
    );
});

// â”€â”€ /ping command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("ping", async (ctx) => {
    const uptime = process.uptime();
    const hours = Math.floor(uptime / 3600);
    const mins = Math.floor((uptime % 3600) / 60);
    const secs = Math.floor(uptime % 60);
    await ctx.reply(`ğŸ“ Pong! Uptime: ${hours}h ${mins}m ${secs}s`);
});

// â”€â”€ /status command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("status", async (ctx) => {
    const chatId = ctx.chat.id;
    const uptimeMs = Date.now() - BOT_START_TIME;
    const hours = Math.floor(uptimeMs / 3_600_000);
    const mins = Math.floor((uptimeMs % 3_600_000) / 60_000);
    const secs = Math.floor((uptimeMs % 60_000) / 1000);
    const memMb = (process.memoryUsage().heapUsed / 1024 / 1024).toFixed(1);
    const msgCount = countMessages(chatId);

    const { getPendingTasks } = await import("./scheduler.js");
    const taskCount = getPendingTasks(chatId).length;

    await ctx.reply(
        `ğŸª **Gravity Claw â€” Status**\n\n` +
        `â€¢ Uptime: ${hours}h ${mins}m ${secs}s\n` +
        `â€¢ Heap: ${memMb} MB\n` +
        `â€¢ Model: \`${LLM_MODEL}\`\n` +
        `â€¢ Context: ${msgCount} msgs\n` +
        `â€¢ Reminders: ${taskCount} pending\n` +
        `â€¢ Node.js: ${process.version}\n`,
        { parse_mode: "Markdown" }
    );
});

// â”€â”€ /model command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("model", async (ctx) => {
    await ctx.reply(
        `ğŸ¤– **Current Model:** \`${LLM_MODEL}\`\n\n` +
        `To switch models, update \`AIML_MODEL\` in \`.env\` and restart.`,
        { parse_mode: "Markdown" }
    );
});

// â”€â”€ /usage command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("usage", async (ctx) => {
    const chatId = ctx.chat.id;
    const summary = getUsageSummary(chatId);
    await ctx.reply(summary, { parse_mode: "Markdown" }).catch(() =>
        ctx.reply(summary)
    );
});

// â”€â”€ /new command (replaces /reset) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("new", async (ctx) => {
    const chatId = ctx.chat.id;
    clearHistory(chatId);
    await ctx.reply("ğŸ§¹ Conversation cleared. Fresh start! What's on your mind?");
});

// â”€â”€ /reset command (alias for /new) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("reset", async (ctx) => {
    const chatId = ctx.chat.id;
    clearHistory(chatId);
    await ctx.reply("ğŸ§¹ Conversation history cleared. Fresh start!");
});

// â”€â”€ /voice command â€” toggle TTS on/off â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("voice", async (ctx) => {
    const chatId = ctx.chat.id;
    if (!isTTSAvailable()) {
        await ctx.reply("âŒ ElevenLabs API key not set. Add ELEVENLABS_API_KEY to .env to enable voice mode.");
        return;
    }
    const current = isVoiceMode(chatId);
    voiceModeEnabled.set(chatId, !current);
    if (!current) {
        await ctx.reply(
            `ğŸ™ï¸ **Voice Mode ON** â€” Jacqueline will speak all responses.\n\n` +
            `Send /voice again to switch back to text.`,
            { parse_mode: "Markdown" }
        );
    } else {
        await ctx.reply("ğŸ’¬ **Voice Mode OFF** â€” back to text responses.", { parse_mode: "Markdown" });
    }
});

// â”€â”€ /reminders command â€” list pending tasks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("reminders", async (ctx) => {
    const chatId = ctx.chat.id;
    const { getPendingTasks } = await import("./scheduler.js");
    const tasks = getPendingTasks(chatId);

    if (tasks.length === 0) {
        await ctx.reply("ğŸ“… You have no pending reminders.");
        return;
    }

    let msg = "ğŸ“… **Upcoming Reminders:**\n\n";
    tasks.forEach((t, i) => {
        const timeStr = new Date(t.scheduled_at * 1000).toLocaleString();
        msg += `${i + 1}. \`${timeStr}\` â€” ${t.message}\n` +
            `   Discard: \`/cancel_${t.id}\`\n\n`;
    });

    await ctx.reply(msg, { parse_mode: "Markdown" });
});

// â”€â”€ /cancel command â€” handles /cancel_{id} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("cancel", async (ctx) => {
    // This handles both /cancel and /cancel_ID via a simple split
    const text = ctx.message?.text || "";
    const id = parseInt(text.split("_")[1]);

    if (isNaN(id)) {
        await ctx.reply("â“ Please provide a reminder ID, e.g., `/cancel_123`", { parse_mode: "Markdown" });
        return;
    }

    const { cancelTask } = await import("./scheduler.js");
    const success = cancelTask(ctx.chat.id, id);

    if (success) {
        await ctx.reply(`âœ… Reminder #${id} cancelled.`);
    } else {
        await ctx.reply(`âŒ Could not find active reminder #${id}.`);
    }
});

// â”€â”€ /compact command â€” context pruning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.command("compact", async (ctx) => {
    const chatId = ctx.chat.id;
    const before = countMessages(chatId);

    if (before <= 10) {
        await ctx.reply(`ğŸ’¬ Only ${before} messages in history â€” no need to compact yet.`);
        return;
    }

    await ctx.replyWithChatAction("typing");

    // Ask the LLM to summarize the current conversation
    try {
        const summary = await runAgent(
            chatId,
            `Please summarize our conversation so far in 3-5 concise bullet points, capturing the key topics and decisions. ` +
            `After your summary, I'll compact the history to just keep the essentials.`
        );

        // Prune to last 10 messages after getting summary
        const pruned = pruneHistory(chatId, 10);
        const after = countMessages(chatId);

        await ctx.reply(
            `ğŸ—œï¸ **Context Compacted**\n\n` +
            `Removed ${pruned} older messages (${before} â†’ ${after} kept).\n\n` +
            `**Summary of what we covered:**\n${summary}`,
            { parse_mode: "Markdown" }
        ).catch(() =>
            ctx.reply(`ğŸ—œï¸ Context compacted: ${before} â†’ ${after} messages.`)
        );
    } catch (error) {
        const pruned = pruneHistory(chatId, 10);
        await ctx.reply(`ğŸ—œï¸ Compacted: removed ${pruned} older messages.`);
    }
});

// â”€â”€ Helper: send response as text or voice â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function sendResponse(ctx: any, chatId: number, response: string): Promise<void> {
    if (isVoiceMode(chatId) && isTTSAvailable()) {
        try {
            await ctx.replyWithChatAction("record_voice");
            const audioBuffer = await textToSpeech(response);
            await ctx.replyWithVoice(new InputFile(audioBuffer, "response.mp3"));
            return;
        } catch (ttsErr) {
            console.error("âŒ TTS error, falling back to text:", ttsErr);
            // Fall through to text reply below
        }
    }
    // Text reply (with chunking for long responses)
    if (response.length <= 4096) {
        await ctx.reply(response, { parse_mode: "Markdown" }).catch(() => ctx.reply(response));
    } else {
        for (const chunk of splitMessage(response, 4000)) {
            await ctx.reply(chunk, { parse_mode: "Markdown" }).catch(() => ctx.reply(chunk));
        }
    }
}

// â”€â”€ Voice message handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.on("message:voice", async (ctx) => {
    const chatId = ctx.chat.id;
    console.log(`  ğŸ™ï¸ Voice message received from ${chatId}`);

    try {
        await ctx.replyWithChatAction("typing");

        const file = await ctx.getFile();
        const fileUrl = `https://api.telegram.org/file/bot${TELEGRAM_BOT_TOKEN}/${file.file_path}`;

        const transcription = await transcribeAudio(fileUrl);

        await ctx.reply(`ğŸ¤ **Transcribed:** _"${transcription}"_`, {
            parse_mode: "Markdown",
            reply_to_message_id: ctx.message.message_id
        });

        const response = await runAgent(chatId, transcription);
        await sendResponse(ctx, chatId, response);
    } catch (error) {
        console.error("âŒ Voice handler error:", error);
        await ctx.reply(
            "âš ï¸ Sorry, I had trouble processing that voice message. " +
            "Could you try speaking again or send it as text?"
        );
    }
});

// â”€â”€ Main message handler (text) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.on("message:text", async (ctx) => {
    const chatId = ctx.chat.id;
    const text = ctx.message.text;

    await ctx.replyWithChatAction("typing");

    try {
        const response = await runAgent(chatId, text);
        await sendResponse(ctx, chatId, response);
    } catch (error) {
        console.error("âŒ Agent error:", error);
        await ctx.reply(
            "âš ï¸ Something went wrong while processing your message. " +
            "Check the server logs for details."
        );
    }
});

// â”€â”€ Error handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bot.catch((err) => {
    console.error("âŒ Bot error:", err.error);
    console.error("   Context:", err.ctx?.update?.update_id);
});

// â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function splitMessage(text: string, maxLength: number): string[] {
    const chunks: string[] = [];
    let remaining = text;

    while (remaining.length > 0) {
        if (remaining.length <= maxLength) {
            chunks.push(remaining);
            break;
        }

        let splitIndex = remaining.lastIndexOf("\n", maxLength);
        if (splitIndex === -1 || splitIndex < maxLength / 2) {
            splitIndex = remaining.lastIndexOf(" ", maxLength);
        }
        if (splitIndex === -1 || splitIndex < maxLength / 2) {
            splitIndex = maxLength;
        }

        chunks.push(remaining.substring(0, splitIndex));
        remaining = remaining.substring(splitIndex).trimStart();
    }

    return chunks;
}
